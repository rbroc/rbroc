---
title: "Developing transformer-based multi-level context encoders"
description: "Transformers that simultaneously produce token- and sequence-level text representations as well as separable representations of the overarching context (author, social media thread) in which the input text is produced"
text: "try"
repo: "personality_reddit" # delete this line if you want a blog-like page
tags: ["NLP", "transformers", "DistilBERT", "TensorFlow", "huggingface", "deep learning", "ML engineering"]
weight: 2
draft: false
---
